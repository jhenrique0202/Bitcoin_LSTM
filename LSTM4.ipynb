{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "azfZFooz69PV"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "%load_ext tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGeVrXox7Dco"
      },
      "source": [
        "def window_data(data):\n",
        "  X = []\n",
        "  Y = []\n",
        "  for d in range(data.shape[0]):\n",
        "    if d >= dias_para_previsao:\n",
        "      X.append(data[d - dias_para_previsao:d])\n",
        "      Y.append(data[d])\n",
        "\n",
        "  X = np.array(X).reshape(-1,dias_para_previsao)\n",
        "  Y = np.array(Y).reshape(-1)\n",
        "  \n",
        "  return X,Y\n",
        "\n",
        "def get_data_set():\n",
        "  with open(\"./predicting-bitcoin-prices-using-LSTM/btc.csv\", \"r\") as f:\n",
        "    f.readline()\n",
        "    data = [float(t.split(\",\")[5]) for t in f.readlines()]\n",
        "  \n",
        "  train_data = np.array(data)\n",
        "  train_data_normalized = scaler.fit_transform(train_data.reshape(-1, 1)).reshape(-1)\n",
        "  \n",
        "  X,Y = window_data(train_data_normalized)\n",
        "  X = torch.from_numpy(X).view(-1,dias_para_previsao, 1)\n",
        "  X.requires_grad_()\n",
        "  X = X.to(torch.float)\n",
        "  Y = torch.from_numpy(Y).view(-1,1)\n",
        "  Y.requires_grad_()\n",
        "  Y = Y.to(torch.float)\n",
        "\n",
        "  train_data_set = TensorDataset(X[:1018], Y[:1018])\n",
        "  test_data_set = TensorDataset(X[1018:], Y[1018:])\n",
        "\n",
        "  train_data_set_complete = DataLoader(train_data_set, batch_size=len(train_data_set))\n",
        "  train_data_set = DataLoader(train_data_set, batch_size=batch_size, shuffle=True)\n",
        "  test_data_set = DataLoader(test_data_set, batch_size=len(test_data_set))\n",
        "  return train_data_set,train_data_set_complete,test_data_set"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFedZ6Vz3gSj"
      },
      "source": [
        "class LSVM_Bitcoin(nn.Module):\n",
        "  def __init__(self, drop_prob=0.5):\n",
        "    super().__init__()\n",
        "    self.LSTM_layers = nn.LSTM(1,num_hidden,num_layers, batch_first=True, dropout = drop_prob)\n",
        "    self.linear_layer1 = nn.Linear(dias_para_previsao*num_hidden,1)\n",
        "    self.bn1 = nn.BatchNorm1d(num_features = dias_para_previsao*num_hidden)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    hidden_cell = (torch.zeros(num_layers,x.shape[0],num_hidden, requires_grad=True).to(torch.float).to(dev),\n",
        "                  torch.zeros(num_layers,x.shape[0],num_hidden, requires_grad=True).to(torch.float).to(dev))\n",
        "    \n",
        "    lstm_out, hidden_cell = self.LSTM_layers(x, hidden_cell)\n",
        "    out = lstm_out.reshape(x.shape[0], -1)\n",
        "        \n",
        "    out = self.sigmoid(self.linear_layer1(self.bn1(out)))\n",
        "    return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7o5NkgHA9X"
      },
      "source": [
        "def get_model():\n",
        "    model = LSVM_Bitcoin()\n",
        "    model = model.to(dev)\n",
        "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "    return model, optimizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vr_VRINHhkZ"
      },
      "source": [
        "def fit(train_data_set,train_data_set_complete,test_data):\n",
        "    model, optimizer = get_model()\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    for e in range(epoch):\n",
        "\n",
        "        for x,y in train_data_set:\n",
        "            x,y = x.to(dev), y.to(dev)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            prediction = model(x)\n",
        "            loss = loss_function(prediction,y)            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        loss = Evaluate_loss(model,loss_function, train_data_set_complete, \"Loss/train\", e=e)\n",
        "        \n",
        "    loss = Evaluate_loss(model,loss_function, test_data, \"Loss/test\")\n",
        "    Compare_graphs(model, train_data_set_complete, test_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHUg2j0nmDvM"
      },
      "source": [
        "def Evaluate_loss(model, loss_function, data_set, kind_data_set, e=0):\n",
        "  for x,y in data_set:\n",
        "    x = x.to(dev)\n",
        "    y = y.to(dev)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = model(x)\n",
        "      loss = loss_function(prediction,y)\n",
        "    graph.add_scalar(kind_data_set, loss, e)\n",
        "    print(\"epoca \" + str(e) + \": \" + kind_data_set + \": \" + str(loss), end = \"\\n\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "def Compare_graphs(model, train_data_set_complete, test_data):\n",
        "  for x,y in train_data_set_complete:\n",
        "    x = x.to(dev)\n",
        "    y = y.to(dev)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = model(x)\n",
        "    for i in range(prediction.shape[0]):\n",
        "      graph.add_scalars(\"Compare_graphs/train\", {\"Original\": y[i], \"Prediction\": prediction[i]},i)\n",
        "\n",
        "  for x,y in test_data:\n",
        "    x = x.to(dev)\n",
        "    y = y.to(dev)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = model(x)\n",
        "    for i in range(prediction.shape[0]):\n",
        "      graph.add_scalars(\"Compare_graphs/test\", {\"Original\": y[i], \"Prediction\": prediction[i]}, i)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBQ2zY4TzxI8"
      },
      "source": [
        "#Hiper Parametros:\n",
        "batch_size=13\n",
        "dias_para_previsao=15\n",
        "epoch=150\n",
        "lr = 8e-4\n",
        "\n",
        "#Parametros:\n",
        "num_layers= 5\n",
        "num_hidden = 12\n",
        "\n",
        "os.system(\"git clone https://github.com/brynmwangy/predicting-bitcoin-prices-using-LSTM.git\")\n",
        "\n",
        "graph = SummaryWriter()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "train_data_set,train_data_set_complete,test_data = get_data_set()\n",
        "\n",
        "fit(train_data_set,train_data_set_complete,test_data)\n",
        "graph.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUhtkxWJOjhF"
      },
      "source": [
        "%tensorboard --logdir=./runs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}